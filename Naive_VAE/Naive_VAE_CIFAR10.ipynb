{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive VAE CIFAR10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3BqHkXn8IC9D0zRrMqwpk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TivoGatto/Thesis/blob/master/Naive_VAE/Naive_VAE_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Heo3fcS5w9VX",
        "colab_type": "text"
      },
      "source": [
        "Implementation of Naive VAE with architecture taken from Tolsikhin et al."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpxulJY8w5wV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LIBRARIES\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, ReLU, Dense, Flatten, Reshape, Conv2DTranspose, Lambda\n",
        "from keras.datasets import cifar10\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iaf7iCDqxrtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "input_dim = (32, 32, 3)\n",
        "latent_dim = 128\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU0TYFOiySzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functions\n",
        "def vae_loss(z_mean, z_log_var):\n",
        "    def loss(x_true, x_pred):\n",
        "        x_true = K.reshape(x_true, (-1, np.prod(input_dim)))\n",
        "        x_pred = K.reshape(x_pred, (-1, np.prod(input_dim)))\n",
        "\n",
        "        L_rec = 0.5 * K.sum(K.square(x_true - x_pred), axis=-1)\n",
        "        L_KL = 0.5 * K.sum(K.square(z_mean) + K.exp(z_log_var) - 1 - z_log_var, axis=-1)\n",
        "\n",
        "        return K.mean(L_rec + L_KL)\n",
        "    return loss\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    eps = K.random_normal(shape=(100, latent_dim)) # 100 = batch_size\n",
        "\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * eps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rofX_33MyUID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test  = x_test.astype('float32')\n",
        "\n",
        "print('x_train shape: ' + str(x_train.shape))\n",
        "print('x_test shape: ' + str(x_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIl6kUx_0h_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Architecture\n",
        "# ENCODER\n",
        "x = Input(shape=input_dim) # Shape (32, 32, 3)\n",
        "\n",
        "h = Conv2D(128, 4, strides=(2, 2), padding='same')(x) # Shape (16, 16, 128)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "h = Conv2D(256, 4, strides=(2, 2), padding='same')(h) # Shape (8, 8, 256)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "h = Conv2D(512, 4, strides=(2, 2), padding='same')(h) # Shape (4, 4, 512)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "h = Conv2D(1024, 4, strides=(2, 2), padding='same')(h) # Shape (2, 2, 1024)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "h = Flatten()(h)\n",
        "\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_var = Dense(latent_dim)(h)\n",
        "z = Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "encoder = Model(x, [z, z_mean, z_log_var])\n",
        "\n",
        "# DECODER\n",
        "z_in = Input(shape=(latent_dim, ))\n",
        "\n",
        "h = Dense(8 * 8 * 1024)(z_in)\n",
        "h = Reshape((8, 8, 1024))(h)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "h = Conv2DTranspose(512, 4, strides=(2, 2), padding='same')(h) # Shape (16, 16, 512)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "h = Conv2DTranspose(256, 4, strides=(2, 2), padding='same')(h) # Shape (32, 32, 256)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "x_decoded = Conv2DTranspose(3, 4, strides=(1, 1), padding='same')(h) # Shape (32, 32, 3)\n",
        "\n",
        "decoder = Model(z_in, x_decoded)\n",
        "\n",
        "# VAE\n",
        "x_recon = decoder(z)\n",
        "\n",
        "vae = Model(x, x_recon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8inwIbj1BMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "optimizer = Adam(lr=0.001)\n",
        "\n",
        "vae.compile(optimizer=optimizer, loss=vae_loss(z_mean, z_log_var))\n",
        "hist = vae.fit(x_train, x_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}